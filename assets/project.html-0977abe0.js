import{_ as l}from"./BayesianNetwork-87a59397.js";import{_ as i}from"./plugin-vue_export-helper-c27b6911.js";import{r as o,o as c,c as d,b as e,e as s,d as n,f as t}from"./app-967c393d.js";const p={},u=e("h2",{id:"requirements",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#requirements","aria-hidden":"true"},"#"),n(" Requirements")],-1),h=e("h2",{id:"instructions",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#instructions","aria-hidden":"true"},"#"),n(" Instructions")],-1),g={class:"hint-container details"},m=e("summary",null,"Instructions",-1),b=e("h3",{id:"marking-guide",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#marking-guide","aria-hidden":"true"},"#"),n(" Marking Guide")],-1),v=t(`<h2 id="dataset" tabindex="-1"><a class="header-anchor" href="#dataset" aria-hidden="true">#</a> Dataset</h2><p><code>BRCA-50</code> is a Breast cancer dataset, including the expression levels of 50 important genes in Breast cancer.</p><ol><li>The dataset includes <span style="color:orange;">1212 samples</span> with</li><li><span style="color:orange;">112 samples</span> are of <span style="color:orange;">normal cases (class = N)</span> and</li><li><span style="color:orange;">1100 samples</span> are of <span style="color:orange;">cancer patients (class = C)</span>.</li></ol><h2 id="tasks" tabindex="-1"><a class="header-anchor" href="#tasks" aria-hidden="true">#</a> Tasks</h2><h3 id="load-library" tabindex="-1"><a class="header-anchor" href="#load-library" aria-hidden="true">#</a> Load library</h3><div class="language-R line-numbers-mode" data-ext="R"><pre class="language-R"><code>library(tidyverse)
library(gRain)
library(pcalg)
library(bnlearn)
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="load-data" tabindex="-1"><a class="header-anchor" href="#load-data" aria-hidden="true">#</a> Load data</h3><div class="language-R line-numbers-mode" data-ext="R"><pre class="language-R"><code>data &lt;- read_csv(&quot;https://seamice.github.io/data/unisa/AdvancedAnalytic2/project/BRCA_RNASeqv2_top50.csv&quot;, col_names = TRUE)
data_no_class &lt;- data %&gt;% select(-class)
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="task-1-causal-structure-cpdag" tabindex="-1"><a class="header-anchor" href="#task-1-causal-structure-cpdag" aria-hidden="true">#</a> Task 1: Causal Structure (CPDAG)</h3><p>Use a <span style="color:orange;">causal structure learning algorithm</span> to <span style="color:orange;">find the gene regulatory network</span>, i.e. the network showing the interactions between genes, using the gene expression data. <span style="color:orange;">Explain how the algorithm works.</span> <span style="color:red;font-weight:bold;">(4)</span></p><div class="hint-container info"><p class="hint-container-title">Hints</p><p>Hints: Please exclude the class variable in building the network</p></div><hr><h4 id="_1-1-learn-the-structure" tabindex="-1"><a class="header-anchor" href="#_1-1-learn-the-structure" aria-hidden="true">#</a> 1.1 <strong>Learn the structure</strong></h4><p>Select the <code>PC</code> algorithm to learn the <code>CPTAG</code></p><div class="language-R line-numbers-mode" data-ext="R"><pre class="language-R"><code>pc.fit &lt;- pc(
  suffStat = list(C = cor(data.no.class), n = nrow(data.no.class)), 
  indepTest = gaussCItest, 
  alpha=0.01, 
  labels = colnames(data.no.class)
  #labels = as.character(1:50)  #label node names
)

#data.frame(NUM=1:50, NAME=colnames(data.no.class))
plot(pc.fit, main = &quot;CPDAG&quot;)
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="_1-2-explain-how-the-algorithm-works" tabindex="-1"><a class="header-anchor" href="#_1-2-explain-how-the-algorithm-works" aria-hidden="true">#</a> 1.2 <strong>Explain how the algorithm works</strong></h4><p><code>PC algorithm</code> is an approach to learn the graph from a data set. The algorithm could be plit into two parts. The first part is to learn the correlation among variables, which is lso called learning skeleton. The second part is to find the direction of the elationship, which is also called as orientating the edges.</p><p><span style="font-weight:bold;color:red;">For this case</span>,</p><hr><p><strong>Learning skeleton</strong></p><p><strong>Input:</strong> Data set <em><strong>D</strong></em>, significant level <em><strong>alpha</strong></em><br><strong>Output:</strong> The undirected graph <em><strong>G</strong></em> with a set of edges <em><strong>E</strong></em></p><p>The first part, the alpha has been set <em><strong>alpha = 0.01</strong></em>, <em><strong>depth = 0</strong></em>, <em><strong>D</strong></em> is the data consist of all variables. Assume that all variables are correlated, the correlation set is <strong>E</strong>*.</p><ul><li><strong>Repeat</strong><ul><li><strong>for</strong> each edges in Graph <em><strong>G</strong></em>, test the <ul><li><strong>If</strong> number of nodes in <em><strong>E</strong></em> is greater or equal <em><strong>depth + 2</strong></em> jump to <strong>NextLevel</strong>, else continue. <ul><li>Test the independence of all nodes pairs from <em><strong>E</strong></em> given condition <em><strong>depth</strong></em> count combination of other variables from <em><strong>E</strong></em>.</li><li><strong>If</strong> the independence exist, <ol><li>remove the correlation from the <em><strong>E</strong></em>.</li><li>Save the condition as the seperation of the two nodes of the edge.</li></ol></li><li><strong>End If</strong></li></ul></li><li><strong>End IF</strong></li></ul></li><li><strong>NextLevel</strong> : <span style="color:red;">set <em><strong>depth = depth + 1</strong></em></span></li></ul></li><li>Until, If number of Node in <em><strong>E</strong></em> is less then <em><strong>depth + 2</strong></em> stop, else continue Repeat.</li></ul><ol start="3"><li><strong>Finally</strong>, get the skeleton of the graph <em><strong>G</strong></em>.</li></ol><hr><p><strong>Orientating the edges</strong></p><p><strong>Input:</strong> Skeleton <em><strong>G</strong></em>, seperation sets <em><strong>S</strong></em><br><strong>Output:</strong> CPDAG <em><strong>G*</strong></em></p><hr><ul><li><strong>for</strong> all nonadjacent variables <em><strong>X</strong></em>, <em><strong>Y</strong></em> with a common neighbor <em><strong>K</strong></em> do <ul><li><strong>If</strong> <em><strong>K</strong></em> does not belongs to separation set of the two nodes <em><strong>S(X,Y)</strong></em> then<br> Replace <em><strong>X-K-J</strong></em> in <em><strong>G</strong></em> by <em><strong>X-&gt;K&lt;-Y</strong></em></li><li><strong>end</strong></li></ul></li><li><strong>end</strong></li></ul><p>Next, orient as many other undirected edges as possible using the following rules:</p><ol><li>Orient <em><strong>X-Y</strong></em> into <em><strong>X-&gt;Y</strong></em> if exists <em><strong>Z-&gt;X</strong></em>, <em><strong>Z</strong></em> and <em><strong>K</strong></em> are onadjacent.</li><li>Orient <em><strong>X-Y</strong></em> into <em><strong>X-&gt;Y</strong></em>, if exists a chain <em><strong>X-&gt;Z-&gt;Y</strong></em>.</li><li>Orient <em><strong>X-Y</strong></em> into <em><strong>X-&gt;Y</strong></em>, if exists two chains <em><strong>X-Z-&gt;Y</strong></em> and <em><strong>X-A-&gt;Y</strong></em>, nd <em><strong>Z</strong></em> and <em><strong>A</strong></em> are nonadjacent.</li></ol><p>Finally, get a CPDAG <em><strong>G*</strong></em></p><h3 id="task-2-causal-effects-ida" tabindex="-1"><a class="header-anchor" href="#task-2-causal-effects-ida" aria-hidden="true">#</a> Task 2: Causal Effects (IDA)</h3><ol start="2"><li><code>EBF1</code> is an important gene that is involved in many biological processes leading to cancer. <span style="color:orange;">Find the top 10 other genes</span> that have strong causal effects on <code>EBF1</code> using a <span style="color:orange;">causal inference algorithm</span>. <span style="color:red;font-weight:bold;">(4)</span><div class="hint-container info"><p class="hint-container-title">Hints</p><ul><li><span style="color:red;">Exclude the class variable</span> in building the network</li><li>If there are <span style="color:red;">multiple possible causal effects</span> between the cause and the effect, we can use the <span style="color:red;">minimum</span> of the absolute values (of the causal effects) as the final result</li><li>The causal effects are normally <span style="color:red;">ranked based on their absolute values</span>.</li></ul></div><hr><strong>Solution</strong>: Using <code>ida</code> to calculate the causal effects of all other variables on <code>EBF1</code> based on the graph built from task 1, then sort the final result base on the values come from <code>ida</code> algorithm.<div class="language-r line-numbers-mode" data-ext="r"><pre class="language-r"><code><span class="token comment"># Get gene EBF1 index</span>
EBF1_idx <span class="token operator">&lt;-</span> match<span class="token punctuation">(</span><span class="token string">&quot;EBF1&quot;</span><span class="token punctuation">,</span> names<span class="token punctuation">(</span>data.no.class<span class="token punctuation">)</span><span class="token punctuation">)</span>
CausalOnEBF1 <span class="token operator">&lt;-</span> data.frame<span class="token punctuation">(</span>
  causality <span class="token operator">=</span> unlist<span class="token punctuation">(</span>
    lapply<span class="token punctuation">(</span>
      <span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">:</span><span class="token number">50</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token operator">-</span>EBF1_idx<span class="token punctuation">]</span><span class="token punctuation">,</span> 
      <span class="token keyword">function</span><span class="token punctuation">(</span>idx<span class="token punctuation">)</span><span class="token punctuation">{</span>
        min<span class="token punctuation">(</span>
          abs<span class="token punctuation">(</span>
            idaFast<span class="token punctuation">(</span>
              idx<span class="token punctuation">,</span>
              EBF1_idx<span class="token punctuation">,</span>
              cov<span class="token punctuation">(</span>data.no.class<span class="token punctuation">)</span><span class="token punctuation">,</span>
              pc.fit<span class="token operator">@</span>graph<span class="token punctuation">)</span>
          <span class="token punctuation">)</span>
        <span class="token punctuation">)</span>
      <span class="token punctuation">}</span>
    <span class="token punctuation">)</span>
  <span class="token punctuation">)</span><span class="token punctuation">,</span>
  variable  <span class="token operator">=</span> names<span class="token punctuation">(</span>data.no.class<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token operator">-</span>EBF1_idx<span class="token punctuation">]</span>
<span class="token punctuation">)</span> 
CausalOnEBF1 <span class="token percent-operator operator">%&gt;%</span> 
  arrange<span class="token punctuation">(</span>across<span class="token punctuation">(</span>causality<span class="token punctuation">,</span> desc<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token punctuation">(</span>CausalOnEBF1 <span class="token percent-operator operator">%&gt;%</span> 
  arrange<span class="token punctuation">(</span>across<span class="token punctuation">(</span>causality<span class="token punctuation">,</span> desc<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">$</span>variable<span class="token punctuation">[</span><span class="token number">1</span><span class="token operator">:</span><span class="token number">10</span><span class="token punctuation">]</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div>According to the result, it could easily get the top 10 genes have strongest causal effects on <code>EBF1</code> are <code>FXYD1</code>, <code>ABCA10</code>, <code>TMEM220</code>, <code>ARHGAP20</code>, <code>FIGF</code>, <code>KLHL29</code>, <code>GPIHBP1</code>, <code>TMEM132C</code>, <code>RDH5</code>, <code>ABCA9</code>.</li></ol><h3 id="task-3-local-causal-structure-markov-blanket" tabindex="-1"><a class="header-anchor" href="#task-3-local-causal-structure-markov-blanket" aria-hidden="true">#</a> Task 3: Local Causal Structure &amp; Markov blanket</h3><ol start="3"><li>Use a <span style="color:orange;">local causal structure learning algorithm</span> to <span style="color:orange;">find genes in the Markov blanket of <code>ABCA9</code> from data</span>. <span style="color:orange;">Explain how the algorithm works</span>. <span style="color:red;font-weight:bold;">(4)</span></li></ol><hr><p><strong>Solution:</strong> We could use local structure learning algorithm <code>IAMB</code> to get the Markov blanket of <code>ABCA9</code> from the data</p><h4 id="_3-1-calculating-the-markov-blanket" tabindex="-1"><a class="header-anchor" href="#_3-1-calculating-the-markov-blanket" aria-hidden="true">#</a> 3.1 Calculating the Markov Blanket</h4><div class="language-R line-numbers-mode" data-ext="R"><pre class="language-R"><code>data.num &lt;- data %&gt;% select(-class)
data.num$class &lt;- ifelse(data$class == &#39;C&#39;, 1, 0)
ABCA9.mb &lt;- learn.mb(
    data.frame(data.num),
    &quot;ABCA9&quot;,
    method = &quot;iamb&quot;, 
    alpha = 0.01
)
ABCA9.mb
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>According to the result above, the Markov Blanket of <code>ABCA9</code> has 23 nodes.</p><h4 id="_3-2-explanation" tabindex="-1"><a class="header-anchor" href="#_3-2-explanation" aria-hidden="true">#</a> 3.2 Explanation</h4><p>The <strong>IAMB</strong> is an abbreviation for <em><strong>Incremental Association Markov Blanket</strong></em>, the algorithm could be separated into two phases, the <em><strong>Growing pahse</strong></em> and <em><strong>Shrinking phase</strong></em>. Details for the two phases are below:<br><strong>CMI:</strong> Conditional mutual information</p><p><strong>Input:</strong> dataset <em><strong>D</strong></em>; target <em><strong>T</strong></em><br><strong>Output:</strong> <em><strong>MB(T)</strong></em></p><hr><p><strong>Growing Phase:</strong></p><ul><li><strong>Repeat</strong> till <em><strong>MB(T)</strong></em> does not change <ul><li>Find the node <em><strong>X</strong></em> from dataset <em><strong>D</strong></em> [exclude all the nodes in <em><strong>MB(T)</strong></em> and <em><strong>T</strong></em>]{style=&quot;color:red&quot;} that has the maximum <strong>CMI</strong></li><li><strong>IF</strong> <em><strong>X</strong></em> independence with <em><strong>T</strong></em> given <em><strong>MB(T)</strong></em>, Then <ul><li><span style="color:red;">Add</span> <em><strong>X</strong></em> to <em><strong>MB(T)</strong></em></li></ul></li><li><strong>End IF</strong></li></ul></li></ul><hr><p><strong>Shrinking Phase:</strong></p><ul><li><strong>For</strong> each node <em><strong>X</strong></em> from <em><strong>MB(T)</strong></em><ul><li><strong>IF</strong> <em><strong>X</strong></em> independence with <em><strong>T</strong></em> given <em><strong>MB(T)</strong></em> [exclude]{style=&quot;color:red&quot;} <em><strong>X</strong></em>, <strong>Then</strong><ul><li><span style="color:red;">Remove</span> <em><strong>X</strong></em> from <em><strong>MB(T)</strong></em></li></ul></li><li><strong>End IF</strong></li></ul></li><li><strong>End For</strong></li></ul><p>Finally, get the final <em><strong>MB(T)</strong></em>.</p><hr><h4 id="references" tabindex="-1"><a class="header-anchor" href="#references" aria-hidden="true">#</a> References</h4>`,53),f={href:"http://www.jcomputers.us/vol5/jcp0511-18.pdf",target:"_blank",rel:"noopener noreferrer"},_={href:"https://cseweb.ucsd.edu//~elkan/254/Verma.pdf",target:"_blank",rel:"noopener noreferrer"},k=t('<h3 id="task-4-discrete-the-dataset" tabindex="-1"><a class="header-anchor" href="#task-4-discrete-the-dataset" aria-hidden="true">#</a> Task 4: Discrete the dataset</h3><ol start="4"><li><span style="color:orange;">Discretise</span> the dataset to binary using the <span style="color:orange;">average expression of ALL genes as the threshold</span>. The discretised dataset will be used in the following questions.</li></ol>',2),y=e("p",null,[e("strong",null,"Solution:"),e("br"),e("strong",null,"Step 1"),n(": Calculating the mean"),e("br"),e("strong",null,"Step 2"),n(": Discrete the data (1: "),e("span",{class:"katex"},[e("span",{class:"katex-mathml"},[e("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[e("semantics",null,[e("mrow",null,[e("mo",null,">")]),e("annotation",{encoding:"application/x-tex"},"\\gt")])])]),e("span",{class:"katex-html","aria-hidden":"true"},[e("span",{class:"base"},[e("span",{class:"strut",style:{height:"0.5782em","vertical-align":"-0.0391em"}}),e("span",{class:"mrel"},">")])])]),n(" mean 0: "),e("span",{class:"katex"},[e("span",{class:"katex-mathml"},[e("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[e("semantics",null,[e("mrow",null,[e("mo",null,"<")]),e("annotation",{encoding:"application/x-tex"},"\\lt")])])]),e("span",{class:"katex-html","aria-hidden":"true"},[e("span",{class:"base"},[e("span",{class:"strut",style:{height:"0.5782em","vertical-align":"-0.0391em"}}),e("span",{class:"mrel"},"<")])])]),n(" mean)")],-1),w=t(`<p>Because of the <code>pcSelect</code> method <span style="color:red;">only support numeric variables</span>, so the discrete variables need to be <span style="color:red;">replaced with 1 and 0 according to <strong>step 2</strong></span>.</p><div class="language-R line-numbers-mode" data-ext="R"><pre class="language-R"><code># The mean of each gene
# mean.val &lt;- as.data.frame(apply(data.no.class, 2, mean))
# The mean of All genes
mean.val &lt;- mean(apply(data.no.class, 2, mean))
names &lt;- colnames(data.no.class)

data.binary &lt;- as.data.frame(
  sapply(
    colnames(data.no.class), 
    function(x) ifelse(data.no.class[,x] &gt;mean.val, 1, 0)
))
data.binary$class &lt;- ifelse(data$class == &#39;C&#39;, 1, 0)


#data.binary.c &lt;- as.data.frame(
#  sapply(
#    colnames(data.no.class), 
#    function(x) ifelse(data.no.class[,x] &gt;mean.val, &#39;T&#39;, &#39;F&#39;)
#))
#data.binary.c$class &lt;- ifelse(data$class == &#39;C&#39;, &#39;T&#39;, &#39;F&#39;)
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="task-5-pc-simple" tabindex="-1"><a class="header-anchor" href="#task-5-pc-simple" aria-hidden="true">#</a> Task 5: PC-Simple</h3><ol start="5"><li>Use <span style="color:orange;">PC-simple algorithm (pcSelect)</span> to <span style="color:orange;">find the parent and children</span> set of the class variable. <span style="color:orange;">Explain how PC-simple works</span>. <ul><li>Evaluate the accuracy of the Naïve Bayes classification on the dataset in the following cases: <ol><li>Use all features (genes) in the dataset</li><li>Use only the features (genes) in the parent and children set of the class variable</li></ol></li><li>Compare the accuracy of the models in the two cases using 10-fold cross validation. <span style="color:red;font-weight:bold;">(6)</span></li></ul></li></ol><p><strong>References:</strong></p>`,5),x={href:"http://www.jcomputers.us/vol5/jcp0511-18.pdf",target:"_blank",rel:"noopener noreferrer"},C={href:"https://cseweb.ucsd.edu//~elkan/254/Verma.pdf",target:"_blank",rel:"noopener noreferrer"},B=e("h4",{id:"_5-1-find-the-parents-and-children",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#_5-1-find-the-parents-and-children","aria-hidden":"true"},"#"),n(" 5.1 Find the parents and children")],-1),T=e("div",{class:"language-text line-numbers-mode","data-ext":"text"},[e("pre",{r:"",class:"language-text"},[e("code",null,`class.pc <- pcSelect(
  data.binary %>% select(class),
  data.binary %>% select(-class),
  alpha = 0.01
)
class.pc <- data.frame(ispc = class.pc$G, zmin = class.pc$zMin)
class.pc[order(class.pc$zmin, decreasing=TRUE),]

rownames(class.pc[class.pc$ispc == TRUE,])
`)]),e("div",{class:"line-numbers","aria-hidden":"true"},[e("div",{class:"line-number"}),e("div",{class:"line-number"}),e("div",{class:"line-number"}),e("div",{class:"line-number"}),e("div",{class:"line-number"}),e("div",{class:"line-number"}),e("div",{class:"line-number"}),e("div",{class:"line-number"}),e("div",{class:"line-number"})])],-1),A=t('<p>According to the result above, it could easily found that the parents and children of <code>class</code> variable are <code>FIGF</code>, <code>ARHGAP20</code>, <code>CD300LG</code>, <code>KLHL29</code>, <code>CXCL2</code>, <code>ATP1A2</code>, <code>MAMDC2</code>, <code>TMEM220</code>, <code>SCARA5</code>, <code>ATOH8</code>.</p><h4 id="_5-2-explanation-of-pc-simple" tabindex="-1"><a class="header-anchor" href="#_5-2-explanation-of-pc-simple" aria-hidden="true">#</a> 5.2 Explanation of PC-Simple</h4><p>PC-Simple is an algorithm to find the parents and children of a target node via conditional independence tests base on a threshold <em><strong>alpha</strong></em>,</p><p><strong>Input:</strong> Dataset <em><strong>D</strong></em> consist of set of predictor variables <em><strong>X</strong></em> and target variable <em><strong>Z</strong></em>; a significant levle <em><strong>alpha</strong></em> for conditional independence test.<br><strong>Output:</strong> The parents and children set <em><strong>PC</strong></em> of target <em><strong>Z</strong></em></p><p><strong>For</strong> this case, the <em><strong>alpha</strong></em> has been set <em><strong>0.01</strong></em>, <em><strong>k = 0</strong></em> , <em><strong>PC(k)</strong></em> equals all other variables.</p><ul><li><strong>Repeat</strong> if count of <em><strong>PC</strong></em> is greater than <em><strong>k</strong></em><ul><li><em><strong>k = k+1</strong></em></li><li><em><strong>PC(k) = PC(k-1)</strong></em></li><li><strong>For</strong> each node <em><strong>X</strong></em> from <em><strong>PC(k-1)</strong></em><ul><li><strong>For</strong> each combination nodes <em><strong>S</strong></em> from <em><strong>PC(k-1)</strong></em> excludes <em><strong>X</strong></em> and count of <em><strong>S</strong></em> equals <em><strong>k-1</strong></em><ul><li><strong>IF</strong> <em><strong>X</strong></em> and <em><strong>Z</strong></em> are independent given <em><strong>S</strong></em> at significance level <em><strong>alpha</strong></em>, Then <ul><li>remove <em><strong>X</strong></em> from <em><strong>PC(K)</strong></em></li></ul></li><li><strong>End IF</strong></li></ul></li><li><strong>End For</strong></li></ul></li><li><em><strong>End For</strong></em></li></ul></li></ul><p>The <em><strong>PC</strong></em> is the final result.</p><h4 id="_5-3-naive-bayes-classification" tabindex="-1"><a class="header-anchor" href="#_5-3-naive-bayes-classification" aria-hidden="true">#</a> 5.3 Naïve Bayes classification</h4>',8),L=e("div",{class:"language-text line-numbers-mode","data-ext":"text"},[e("pre",{r:"",class:"language-text"},[e("code",null,`library(caret)
`)]),e("div",{class:"line-numbers","aria-hidden":"true"},[e("div",{class:"line-number"})])],-1),G=e("h5",{id:"_5-3-1-naive-bayes-classification-with-all-features",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#_5-3-1-naive-bayes-classification-with-all-features","aria-hidden":"true"},"#"),n(" 5.3.1 Naive Bayes classification with all features")],-1),F=e("div",{class:"language-text line-numbers-mode","data-ext":"text"},[e("pre",{r:"",class:"language-text"},[e("code",null,`set.seed(100)
trctrl <- trainControl(method = "cv", number = 10, savePredictions=TRUE)
nb_all <- train(
  factor(class) ~., 
  data = data.binary, 
  method = "naive_bayes", 
  trControl=trctrl, 
  tuneLength = 0
)
nb_all
`)]),e("div",{class:"line-numbers","aria-hidden":"true"},[e("div",{class:"line-number"}),e("div",{class:"line-number"}),e("div",{class:"line-number"}),e("div",{class:"line-number"}),e("div",{class:"line-number"}),e("div",{class:"line-number"}),e("div",{class:"line-number"}),e("div",{class:"line-number"}),e("div",{class:"line-number"}),e("div",{class:"line-number"})])],-1),D=e("h5",{id:"_5-3-2-naive-bayes-classification-with-related-features",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#_5-3-2-naive-bayes-classification-with-related-features","aria-hidden":"true"},"#"),n(" 5.3.2 Naive Bayes classification with related features")],-1),I=e("div",{class:"language-text line-numbers-mode","data-ext":"text"},[e("pre",{r:"",class:"language-text"},[e("code",null,`data.binary.related <- data.binary[,append(rownames(class.pc[class.pc$ispc == TRUE,]), "class")]
nb_pc <- train(
  factor(class) ~., 
  data = data.binary.related, 
  method = "naive_bayes", 
  trControl=trctrl, 
  tuneLength = 0
)
nb_pc
`)]),e("div",{class:"line-numbers","aria-hidden":"true"},[e("div",{class:"line-number"}),e("div",{class:"line-number"}),e("div",{class:"line-number"}),e("div",{class:"line-number"}),e("div",{class:"line-number"}),e("div",{class:"line-number"}),e("div",{class:"line-number"}),e("div",{class:"line-number"}),e("div",{class:"line-number"})])],-1),E=t(`<h5 id="_5-3-3-comparision-between-the-two-models" tabindex="-1"><a class="header-anchor" href="#_5-3-3-comparision-between-the-two-models" aria-hidden="true">#</a> 5.3.3 Comparision between the two models</h5><div class="language-R line-numbers-mode" data-ext="R"><pre class="language-R"><code>confusionMatrix(nb_all)
confusionMatrix(nb_pc)
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><p>According to the confusion matrix, we could get indicators table like below.</p><table><thead><tr><th>indicators</th><th><em><strong>ma</strong></em></th><th><em><strong>mr</strong></em></th></tr></thead><tbody><tr><td><strong>accuracy</strong></td><td>0.9761</td><td><span style="color:red;">0.9843</span></td></tr><tr><td><strong>precision(1)</strong> : cancer</td><td><span style="color:red;">0.9982</span></td><td>0.9809</td></tr><tr><td><strong>precision(0)</strong>: normal</td><td>0.7589</td><td><span style="color:red;">1</span></td></tr><tr><td><strong>recall(1)</strong>: cancer</td><td>0.9760</td><td><span style="color:red;">1</span></td></tr><tr><td><strong>recall(0)</strong>: normal</td><td><span style="color:red;">0.9770</span></td><td>0.8421</td></tr></tbody></table><p>The precision stands for the accuracy of prediction cases, the recall represents the accuracy of actual cases that has been recognized. According to the table above, the overall accuracy of <em><strong>mr</strong></em> is better than <em><strong>ma</strong></em>. For cancer cases, the <em><strong>ma</strong></em> perform better than <em><strong>mr</strong></em> on prediction, but for recall value of <em><strong>mr</strong></em> is better than <em><strong>ma</strong></em>. For normal cases, the <em><strong>mr</strong></em> works better than <em><strong>ma</strong></em> on precision, but the <em><strong>ma</strong></em> perform better on recall than <em><strong>mr</strong></em>.</p><h3 id="task-6-calculating-based-on-specified-dag" tabindex="-1"><a class="header-anchor" href="#task-6-calculating-based-on-specified-dag" aria-hidden="true">#</a> Task 6: Calculating based on specified DAG</h3><ol start="6"><li>Given a Bayesian network as in the below figure<br><img src="`+l+`" alt="" loading="lazy"></li></ol><h4 id="_6-1-a-construct-the-conditional-probability-tables-for-the-bayesian-network-based-on-data-3" tabindex="-1"><a class="header-anchor" href="#_6-1-a-construct-the-conditional-probability-tables-for-the-bayesian-network-based-on-data-3" aria-hidden="true">#</a> 6.1 a) <span style="color:orange;">Construct the conditional probability tables</span> for the Bayesian network based on data. <span style="color:red;font-weight:bold;">(3)</span></h4><h5 id="_6-1-1-construct-using-grain" tabindex="-1"><a class="header-anchor" href="#_6-1-1-construct-using-grain" aria-hidden="true">#</a> 6.1.1 Construct using <code>gRain</code></h5><p>For constructing the net, using the <em><strong>T</strong></em> instead of <em><strong>1</strong></em> and using <em><strong>F</strong></em> instead of <em><strong>0</strong></em>.</p><div class="language-R line-numbers-mode" data-ext="R"><pre class="language-R"><code>data.graph &lt;- data.binary %&gt;% select(BTNL9,CD300LG,class,IGSF10,ABCA9)

yn &lt;- c(&#39;T&#39;,&#39;F&#39;)

B     &lt;- cptable(~BTNL9, 
                 values= (data.graph %&gt;% 
                            select(BTNL9) %&gt;%
                            group_by(BTNL9) %&gt;%
                            count() %&gt;%
                            arrange(across(BTNL9, desc)))$n,
                 levels=yn)
CD.B  &lt;- cptable(~CD300LG|BTNL9, 
                 values=(data.graph %&gt;% 
                            select(CD300LG, BTNL9) %&gt;%
                            group_by(CD300LG, BTNL9) %&gt;%
                            count() %&gt;%
                            arrange(across(BTNL9, desc),
                                    across(CD300LG, desc)))$n,
                 levels=yn)
c.CD  &lt;- cptable(~class|CD300LG, 
                 values=(data.graph %&gt;% 
                            select(class, CD300LG) %&gt;%
                            group_by(class, CD300LG) %&gt;%
                            count() %&gt;%
                            arrange(across(CD300LG, desc),
                                    across(class, desc)))$n, 
                 levels=yn)
I.c   &lt;- cptable(~IGSF10|class, 
                 values=(data.graph %&gt;% 
                            select(IGSF10, class) %&gt;%
                            group_by(IGSF10, class) %&gt;%
                            count() %&gt;%
                            arrange(across(class, desc), 
                                    across(IGSF10, desc)
                                    ))$n, 
                 levels=yn)

AB.B_I&lt;- cptable(~ABCA9|BTNL9:IGSF10,
                 values=(data.graph %&gt;% 
                            select(ABCA9, BTNL9,IGSF10) %&gt;%
                            group_by(ABCA9, BTNL9,IGSF10) %&gt;%
                            count() %&gt;%
                            arrange( 
                              across(IGSF10, desc), 
                              across(BTNL9, desc),
                              across(ABCA9, desc)))$n,
                 levels=yn)

plist &lt;- compileCPT(list(B, CD.B, c.CD, I.c, AB.B_I))
plist
net=grain(plist) 

plot(net$dag)
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h5 id="_6-1-2-construct-using-bnlearn" tabindex="-1"><a class="header-anchor" href="#_6-1-2-construct-using-bnlearn" aria-hidden="true">#</a> 6.1.2 Construct using <code>bnlearn</code></h5><blockquote></blockquote>`,13),R=e("div",{class:"language-text line-numbers-mode","data-ext":"text"},[e("pre",{r:"",class:"language-text"},[e("code",null,`bn.dag = model2network("[BTNL9][CD300LG|BTNL9][ABCA9|BTNL9:IGSF10][class|CD300LG][IGSF10|class]")
graphviz.plot(bn.dag)
`)]),e("div",{class:"line-numbers","aria-hidden":"true"},[e("div",{class:"line-number"}),e("div",{class:"line-number"})])],-1),M=e("ul",null,[e("li",null,"learn parameters from data")],-1),S=e("div",{class:"language-text line-numbers-mode","data-ext":"text"},[e("pre",{r:"",class:"language-text"},[e("code",null,`bn.fitted <- bn.fit(
  bn.dag,
  data.binary %>% select(BTNL9, CD300LG, class, IGSF10, ABCA9)
) 
`)]),e("div",{class:"line-numbers","aria-hidden":"true"},[e("div",{class:"line-number"}),e("div",{class:"line-number"}),e("div",{class:"line-number"}),e("div",{class:"line-number"})])],-1),N=t('<h4 id="_6-2-b-estimate-the-probability-of-the-four-genes-in-the-network-having-high-expression-levels-2" tabindex="-1"><a class="header-anchor" href="#_6-2-b-estimate-the-probability-of-the-four-genes-in-the-network-having-high-expression-levels-2" aria-hidden="true">#</a> 6.2 b) <span style="color:orange;">Estimate the probability of the four genes</span> in the network having high expression levels. <span style="color:red;font-weight:bold;">(2)</span></h4><p>This question aims to calculate the <em><strong>joint probability</strong></em> of the four genes in the network for each value of the four variables equal <em><strong>T</strong></em>. It could be expressed with the formula <em><strong>P(BTNL9=T, CD300LG=T, IGSF10=T, ABCA9=T)</strong></em>.</p><h5 id="_6-2-1-method-1" tabindex="-1"><a class="header-anchor" href="#_6-2-1-method-1" aria-hidden="true">#</a> 6.2.1 Method 1</h5>',3),P=e("div",{class:"language-text line-numbers-mode","data-ext":"text"},[e("pre",{r:"",class:"language-text"},[e("code",null,`querygrain(net, nodes=c("BTNL9", "CD300LG", "IGSF10", "ABCA9"), type="joint")
`)]),e("div",{class:"line-numbers","aria-hidden":"true"},[e("div",{class:"line-number"})])],-1),q=e("p",null,[n("According to the table above, it could get the "),e("em",null,[e("strong",null,[n("P(BTNL9=T, CD300LG=T, IGSF10=T, ABCA9=T)="),e("span",{style:{color:"red"}},"0.073736")])])],-1),j=e("h5",{id:"_6-2-2-method-2",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#_6-2-2-method-2","aria-hidden":"true"},"#"),n(" 6.2.2 Method 2")],-1),X=e("div",{class:"language-text line-numbers-mode","data-ext":"text"},[e("pre",{r:"",class:"language-text"},[e("code",null,`joint_pb <- setEvidence(
  net, 
  evidence=list(BTNL9="T", CD300LG="T",  IGSF10="T", ABCA9="T")
)
pEvidence(joint_pb)
`)]),e("div",{class:"line-numbers","aria-hidden":"true"},[e("div",{class:"line-number"}),e("div",{class:"line-number"}),e("div",{class:"line-number"}),e("div",{class:"line-number"}),e("div",{class:"line-number"})])],-1),z=t('<p>According to the table above, it could get the same result with method 1.</p><h4 id="_6-3-c-estimate-the-probability-of-having-cancer-when-the-expression-level-of-cd300lg-is-high-and-the-expression-level-of-btnl9-is-low-2" tabindex="-1"><a class="header-anchor" href="#_6-3-c-estimate-the-probability-of-having-cancer-when-the-expression-level-of-cd300lg-is-high-and-the-expression-level-of-btnl9-is-low-2" aria-hidden="true">#</a> 6.3 c) <span style="color:orange;">Estimate the probability of having cancer</span> when the expression level of <code>CD300LG</code> is high and the expression level of <code>BTNL9</code> is low. <span style="color:red;font-weight:bold;">(2)</span></h4><blockquote><p>This question actually ask us to calculate the conditional probability <em><strong>P(class=T| CD300LG=T, BTNL9=F)</strong></em>, here I will use <code>cpquery</code> method for get the conditional probability.</p></blockquote>',3),$=e("div",{class:"language-text line-numbers-mode","data-ext":"text"},[e("pre",{r:"",class:"language-text"},[e("code",null,`querygrain(net, nodes=c("class","CD300LG","BTNL9"), type="conditional")
`)]),e("div",{class:"line-numbers","aria-hidden":"true"},[e("div",{class:"line-number"})])],-1),O=t(`<p>So the final result <em><strong>P(class=T|CD300LG=T,BTNL9=F)</strong></em> = <span style="color:red;"><em><strong>0.2585034</strong></em></span></p><h4 id="_6-4-d-prove-the-result-in-c-mathematically-2" tabindex="-1"><a class="header-anchor" href="#_6-4-d-prove-the-result-in-c-mathematically-2" aria-hidden="true">#</a> 6.4 d) <span style="color:orange;">Prove the result in c) mathematically</span>. <span style="color:red;font-weight:bold;">(2)</span></h4><div class="language-R line-numbers-mode" data-ext="R"><pre class="language-R"><code>data.graph %&gt;% 
  select(class, CD300LG,BTNL9) %&gt;%
  group_by(class, CD300LG,BTNL9) %&gt;%
  count() %&gt;%
  arrange( 
    across(class, desc), 
    across(CD300LG, desc),
    across(BTNL9, desc))
#plot(net$dag)
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>According to the graph, <code>BTNL9</code> is the parent of <code>CD300LG</code>, so</p><p><em><strong>P(class=T| BTNL9=F,CD300LG=T)</strong></em><br><em><strong>= P(class=T|CD300LG=T)</strong></em><br><em><strong>= (32+6)/(32+107+6+2)</strong></em><br> = <span style="color:red;"><em><strong>0.2585034</strong></em></span></p><h4 id="_6-5-e-given-we-know-the-value-of-cd300lg-is-the-class-conditionally-independent-of-abca9-and-why-3" tabindex="-1"><a class="header-anchor" href="#_6-5-e-given-we-know-the-value-of-cd300lg-is-the-class-conditionally-independent-of-abca9-and-why-3" aria-hidden="true">#</a> 6.5 e) Given we know the value of <code>CD300LG</code>, is the “class” <span style="color:orange;">conditionally independent</span> of <code>ABCA9</code>? And why? <span style="color:red;font-weight:bold;">(3)</span></h4><p><strong>Anwser:</strong> <span style="color:red;"><strong>No</strong></span></p><p><strong>Explanation:</strong> According to Markov condition, every node in a Bayesian network is conditionally independent of its nondescendants, given its parents. So the parent <code>CD300LG</code> of <code>class</code> is given, <code>ABCA9</code> is the descendant of <code>class</code> variable, so the <code>class</code> is not conditionally independent of <code>ABCA9</code>.</p><hr>`,9),U=e("a",{href:"/data/unisa/AdvancedAnalytic2/project/Project.Rmd"},"Download RMD",-1),Y=e("br",null,null,-1),H={href:"https://colab.research.google.com/drive/13V7I9g8k69c61NJzuwc80PwrOwM-Dz-0?usp=sharing",target:"_blank",rel:"noopener noreferrer"},V=e("h2",{id:"references-1",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#references-1","aria-hidden":"true"},"#"),n(" References")],-1),K=e("br",null,null,-1),Z={href:"http://www.sci-princess.info/wp-content/uploads/Causal-Graphs-and-the-PC-Algorithm.pdf",target:"_blank",rel:"noopener noreferrer"},J=e("br",null,null,-1),W={href:"https://pooyanjamshidi.github.io/csce580/lectures/CSCE580-GuestLecture%E2%80%93BNLearning.pdf",target:"_blank",rel:"noopener noreferrer"},Q=e("br",null,null,-1),ee={href:"https://arxiv.org/pdf/0908.3817.pdf",target:"_blank",rel:"noopener noreferrer"},ne=e("br",null,null,-1),se={href:"https://www.bnlearn.com/about/slides/slides-useRconf13.pdf",target:"_blank",rel:"noopener noreferrer"},ae=e("br",null,null,-1),te={href:"https://stat.ethz.ch/Manuscripts/buhlmann/pcalg-software.pdf",target:"_blank",rel:"noopener noreferrer"},re=e("br",null,null,-1),oe={href:"https://cran.r-project.org/web/packages/pcalg/pcalg.pdf",target:"_blank",rel:"noopener noreferrer"},le=e("br",null,null,-1),ie={href:"https://cran.r-project.org/web/packages/pcalg/vignettes/vignette2018.pdf",target:"_blank",rel:"noopener noreferrer"},ce=e("br",null,null,-1),de={href:"https://www.bnlearn.com/examples/graphviz-plot/",target:"_blank",rel:"noopener noreferrer"},pe=e("br",null,null,-1),ue={href:"https://www.bnlearn.com/documentation/man/cpquery.html",target:"_blank",rel:"noopener noreferrer"},he=e("br",null,null,-1),ge={href:"https://rdrr.io/github/vspinu/bnlearn/man/cpquery.html",target:"_blank",rel:"noopener noreferrer"},me=e("br",null,null,-1),be={href:"https://dipartimenti.unicatt.it/scienze-statistiche-23-25-1-17ScutariSlides.pdf",target:"_blank",rel:"noopener noreferrer"},ve=e("br",null,null,-1),fe={href:"https://rdrr.io/bioc/Rgraphviz/man/GraphvizAttributes.html#:~:text=Font%20size%2C%20in%20points%2C%20for,Label%20for%20the%20graph.",target:"_blank",rel:"noopener noreferrer"},_e=e("br",null,null,-1),ke={href:"https://www.cs.cmu.edu/afs/cs/project/jair/pub/volume18/acid03a-html/node2.html",target:"_blank",rel:"noopener noreferrer"},ye=e("br",null,null,-1),we={href:"https://www.cnblogs.com/payton/articles/4608383.html",target:"_blank",rel:"noopener noreferrer"};function xe(Ce,Be){const r=o("PDF"),a=o("ExternalLinkIcon");return c(),d("div",null,[u,h,e("details",g,[m,s(r,{url:"/data/unisa/AdvancedAnalytic2/project/project.pdf",ratio:"1.4"}),b,s(r,{url:"/data/unisa/AdvancedAnalytic2/project/Marking Guidelines - Project.pdf",ratio:"1.4"})]),v,e("p",null,[n("[01]. "),e("a",f,[n("An Improved IAMB Algorithm for Markov Blanket Discovery"),s(a)])]),e("p",null,[n("[02]. "),e("a",_,[n("Discovering Markov Blankets: Finding Independencies Among Variables"),s(a)])]),k,y,w,e("ol",null,[e("li",null,[e("a",x,[n("An Improved IAMB Algorithm for Markov Blanket Discovery"),s(a)])]),e("li",null,[e("a",C,[n("Discovering Markov Blankets: Finding Independencies Among Variables"),s(a)])])]),B,T,A,L,G,F,D,I,E,R,M,S,N,P,q,j,X,z,$,O,e("p",null,[U,Y,e("a",H,[n("online code"),s(a)])]),V,e("p",null,[n("Algorithm:"),K,e("a",Z,[n("http://www.sci-princess.info/wp-content/uploads/Causal-Graphs-and-the-PC-Algorithm.pdf"),s(a)]),J,e("a",W,[n("https://pooyanjamshidi.github.io/csce580/lectures/CSCE580-GuestLecture--BNLearning.pdf"),s(a)]),Q,e("a",ee,[n("https://arxiv.org/pdf/0908.3817.pdf"),s(a)]),ne,e("a",se,[n("https://www.bnlearn.com/about/slides/slides-useRconf13.pdf"),s(a)])]),e("p",null,[n("pcalg:"),ae,e("a",te,[n("https://stat.ethz.ch/Manuscripts/buhlmann/pcalg-software.pdf"),s(a)]),re,e("a",oe,[n("https://cran.r-project.org/web/packages/pcalg/pcalg.pdf"),s(a)]),le,e("a",ie,[n("https://cran.r-project.org/web/packages/pcalg/vignettes/vignette2018.pdf"),s(a)])]),e("p",null,[n("bnlearn:"),ce,e("a",de,[n("https://www.bnlearn.com/examples/graphviz-plot/"),s(a)]),pe,e("a",ue,[n("https://www.bnlearn.com/documentation/man/cpquery.html"),s(a)]),he,e("a",ge,[n("https://rdrr.io/github/vspinu/bnlearn/man/cpquery.html"),s(a)]),me,e("a",be,[n("https://dipartimenti.unicatt.it/scienze-statistiche-23-25-1-17ScutariSlides.pdf"),s(a)])]),e("p",null,[n("Graphviz"),ve,e("a",fe,[n("https://rdrr.io/bioc/Rgraphviz/man/GraphvizAttributes.html#:~:text=Font size%2C in points%2C for,Label for the graph."),s(a)]),_e,e("a",ke,[n("https://www.cs.cmu.edu/afs/cs/project/jair/pub/volume18/acid03a-html/node2.html"),s(a)])]),e("p",null,[n("Chinese Sample:"),ye,e("a",we,[n("https://www.cnblogs.com/payton/articles/4608383.html"),s(a)])])])}const Ge=i(p,[["render",xe],["__file","project.html.vue"]]);export{Ge as default};
