const e=JSON.parse(`{"key":"v-2e88261e","path":"/unisa/2023SP5/AdvancedAnalyticTechniques2/practices.03.html","title":"Practices Part3","lang":"en-US","frontmatter":{"title":"Practices Part3","index":true,"icon":"/assets/icon/common/flags.svg","icon-size":"4rem","author":"Haiyue","date":"2023-10-19T00:00:00.000Z","category":["classfier"],"description":"Week 8: Data Stream Mining In this practical, we use the stream R package for analysing stream data. Please install the stream package to complete the practical. I. Creating a data stream We firstly create a generator to generate stream data points that will belong to one of three clusters (k=3). Each data point will have 2 dimensions (d=2). The data points will follow Gaussian distribution with 5% noise. When a new data point is requested from this data generator, a cluster will be chosen randomly using the probability weights in p. library(\\"stream\\") stream &lt;- DSD_Gaussians(k = 3, d = 2, noise = .05, p = c(.5, .3, .1)) stream Generate 5 data points using the generator.","head":[["meta",{"property":"og:url","content":"https://seamice.github.io/blog/unisa/2023SP5/AdvancedAnalyticTechniques2/practices.03.html"}],["meta",{"property":"og:site_name","content":"Haiyue's Blog"}],["meta",{"property":"og:title","content":"Practices Part3"}],["meta",{"property":"og:description","content":"Week 8: Data Stream Mining In this practical, we use the stream R package for analysing stream data. Please install the stream package to complete the practical. I. Creating a data stream We firstly create a generator to generate stream data points that will belong to one of three clusters (k=3). Each data point will have 2 dimensions (d=2). The data points will follow Gaussian distribution with 5% noise. When a new data point is requested from this data generator, a cluster will be chosen randomly using the probability weights in p. library(\\"stream\\") stream &lt;- DSD_Gaussians(k = 3, d = 2, noise = .05, p = c(.5, .3, .1)) stream Generate 5 data points using the generator."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"en-US"}],["meta",{"property":"og:updated_time","content":"2023-10-19T11:22:38.000Z"}],["meta",{"property":"article:author","content":"Haiyue"}],["meta",{"property":"article:published_time","content":"2023-10-19T00:00:00.000Z"}],["meta",{"property":"article:modified_time","content":"2023-10-19T11:22:38.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"Practices Part3\\",\\"image\\":[\\"\\"],\\"datePublished\\":\\"2023-10-19T00:00:00.000Z\\",\\"dateModified\\":\\"2023-10-19T11:22:38.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"Haiyue\\"}]}"]]},"headers":[{"level":2,"title":"Week 8: Data Stream Mining","slug":"week-8-data-stream-mining","link":"#week-8-data-stream-mining","children":[{"level":3,"title":"I. Creating a data stream","slug":"i-creating-a-data-stream","link":"#i-creating-a-data-stream","children":[]},{"level":3,"title":"II. Reading and writing data streams","slug":"ii-reading-and-writing-data-streams","link":"#ii-reading-and-writing-data-streams","children":[]},{"level":3,"title":"III. Reservoir Sampling","slug":"iii-reservoir-sampling","link":"#iii-reservoir-sampling","children":[]},{"level":3,"title":"IV. Data Stream Clustering","slug":"iv-data-stream-clustering","link":"#iv-data-stream-clustering","children":[]}]},{"level":2,"title":"Week 10: Data Stream Mining","slug":"week-10-data-stream-mining","link":"#week-10-data-stream-mining","children":[{"level":3,"title":"I. Evaluation of data stream clustering","slug":"i-evaluation-of-data-stream-clustering","link":"#i-evaluation-of-data-stream-clustering","children":[]},{"level":3,"title":"II. Concept Drift","slug":"ii-concept-drift","link":"#ii-concept-drift","children":[]},{"level":3,"title":"III. Evaluation of data stream clustering with concept drift","slug":"iii-evaluation-of-data-stream-clustering-with-concept-drift","link":"#iii-evaluation-of-data-stream-clustering-with-concept-drift","children":[]}]}],"git":{"createdTime":1697714558000,"updatedTime":1697714558000,"contributors":[{"name":"Haiyue","email":"nutterair1989@gmail.com","commits":1}]},"readingTime":{"minutes":3.04,"words":912},"filePathRelative":"unisa/2023SP5/AdvancedAnalyticTechniques2/practices.03.md","localizedDate":"October 19, 2023","excerpt":"<h2> Week 8: Data Stream Mining</h2>\\n<p>In this practical, we use the stream R package for analysing stream data. Please install the stream package to complete the practical.</p>\\n<h3> I. Creating a data stream</h3>\\n<ol>\\n<li>\\n<p>We firstly create a generator to generate stream data points that will belong to one of three clusters <code>(k=3)</code>. Each data point will have 2 dimensions <code>(d=2)</code>. The data points will follow Gaussian distribution with 5% noise. When a new data point is requested from this data generator, a cluster will be chosen randomly using the probability weights in <code>p</code>.</p>\\n<div class=\\"language-R line-numbers-mode\\" data-ext=\\"R\\"><pre class=\\"language-R\\"><code>library(\\"stream\\")\\nstream &lt;- DSD_Gaussians(k = 3, d = 2, noise = .05, p = c(.5, .3, .1))\\nstream\\n</code></pre><div class=\\"line-numbers\\" aria-hidden=\\"true\\"><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div></div></div></li>\\n<li>\\n<p>Generate 5 data points using the generator.</p>\\n</li>\\n</ol>","autoDesc":true}`);export{e as data};
