import{_ as r}from"./plugin-vue_export-helper-c27b6911.js";import{r as a,o,c as l,b as e,d as n,e as t,f as d}from"./app-a7b366b7.js";const s={},c={href:"https://rumn.medium.com/part-1-ultimate-guide-to-fine-tuning-in-pytorch-pre-trained-model-and-its-configuration-8990194b71e",target:"_blank",rel:"noopener noreferrer"},h={href:"https://rumn.medium.com/ultimate-guide-to-fine-tuning-in-pytorch-part-3-deep-dive-to-pytorch-data-transforms-53ed29d18dde",target:"_blank",rel:"noopener noreferrer"},u={href:"https://huggingface.co/docs/transformers/training",target:"_blank",rel:"noopener noreferrer"},p={href:"https://pytorch.org/tutorials/intermediate/torchvision_tutorial.html",target:"_blank",rel:"noopener noreferrer"},f={href:"https://www.kaggle.com/code/rajkumarl/nlp-tutorial-fine-tuning-in-pytorch",target:"_blank",rel:"noopener noreferrer"},g=d('<h2 id="parts" tabindex="-1"><a class="header-anchor" href="#parts" aria-hidden="true">#</a> Parts</h2><p>This article is divided into four parts, with each part focusing on different aspects of fine-tuning models.</p><p>Part 1 : We will delve into defining a pre-trained model and configuring it to suit your target task.<br> Part 2 : The second part will explore various techniques to enhance the accuracy of your fine-tuned model.<br> Part 3 : Moving on to Part Three, we will cover the process of Defining Data and Applying Transformations tailored specifically to your target task.<br> Part 4 : Finally, in the last of this series, we’ll address Model Training Observability, including which metrics to track during training and how to effectively manage model checkpoints, among other important aspects.</p><h2 id="outlines" tabindex="-1"><a class="header-anchor" href="#outlines" aria-hidden="true">#</a> Outlines</h2><ul><li>Introduction — The Model and Its Configuration</li><li>Loading a pre-trained model</li><li>Modifying model head</li><li>Setting Learning Rate, Optimizer and Weight Decay</li><li>Choosing Loss Function</li><li>Freezing Full or Partial network</li><li>Define Model Floating-point precision</li><li>Training and Validation Mode</li><li>Single GPU and Multi GPU</li><li>Conclusion</li></ul><h1 id="introduction" tabindex="-1"><a class="header-anchor" href="#introduction" aria-hidden="true">#</a> Introduction</h1><p>Defining a model includes a range of important decisions, including selecting the appropriate architecture, customizing the model head, configuring the loss function and learning rate, setting the desired floating-point precision, and determining which layers to freeze or fine-tune, and many more. In this article, we will explore each of these aspects in detail, providing valuable insights to help you effectively define and fine tune your model.</p><h1 id="loading-a-pre-trained-model" tabindex="-1"><a class="header-anchor" href="#loading-a-pre-trained-model" aria-hidden="true">#</a> Loading a pre-trained model</h1>',8);function m(_,y){const i=a("ExternalLinkIcon");return o(),l("div",null,[e("ol",null,[e("li",null,[e("a",c,[n("Ultimate Guide to Fine-Tuning in PyTorch : Part 1 — Pre-trained Model and Its Configuration"),t(i)])]),e("li",null,[e("a",h,[n("Ultimate Guide to Fine-Tuning in PyTorch : Part 3 —Deep Dive to PyTorch Data Transforms with Examples"),t(i)])]),e("li",null,[e("a",u,[n("Fine-tune a pretrained model"),t(i)])]),e("li",null,[e("a",p,[n("TORCHVISION OBJECT DETECTION FINETUNING TUTORIAL"),t(i)])]),e("li",null,[e("a",f,[n("[NLP Tutorial] Fine-Tuning in PyTorch"),t(i)])])]),g])}const P=r(s,[["render",m],["__file","pytorch_finetune.html.vue"]]);export{P as default};
