import{_ as n}from"./plugin-vue_export-helper-c27b6911.js";import{r as t,o as l,c as s,b as e,d as o,e as a}from"./app-7f852aec.js";const c={},i=e("h2",{id:"previous-work",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#previous-work","aria-hidden":"true"},"#"),o(" Previous work")],-1),h={href:"https://colab.research.google.com/drive/11vliXWcRSSwZe027Z5wMn7ne7TH3H64j?usp=sharing",target:"_blank",rel:"noopener noreferrer"},_=e("h2",{id:"resources",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#resources","aria-hidden":"true"},"#"),o(" Resources")],-1),d={href:"https://lachieslifestyle.com/2023/07/29/how-to-install-llama-2/",target:"_blank",rel:"noopener noreferrer"},p=e("br",null,null,-1),m=e("a",{href:""},"lmstudio.ai",-1),u=e("br",null,null,-1),f={href:"https://aws.amazon.com/blogs/aws/amazon-bedrock-now-provides-access-to-llama-2-chat-13b-model/",target:"_blank",rel:"noopener noreferrer"},b={href:"https://pypi.org/project/llama-server/",target:"_blank",rel:"noopener noreferrer"},k=e("br",null,null,-1),w={href:"https://www.philschmid.de/inferentia2-llama-7b",target:"_blank",rel:"noopener noreferrer"};function g(v,x){const r=t("ExternalLinkIcon");return l(),s("div",null,[i,e("p",null,[e("a",h,[o("Event Ranking"),a(r)])]),_,e("p",null,[e("a",d,[o("How to use LLama Model locally"),a(r)]),p,m,u,e("a",f,[o("Llama 2 Chat 13B now supported in Amazon Bedrock"),a(r)])]),e("p",null,[e("a",b,[o("llama-server"),a(r)]),k,e("a",w,[o("Deploy Llama 2 7B on AWS inferentia2 with Amazon SageMaker"),a(r)])])])}const B=n(c,[["render",g],["__file","GenAI_Locally.html.vue"]]);export{B as default};
